{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Introduction to Spark In-memory Computing via Python PySpark </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching Spark cluster with the following parameters:\n",
      "Master Node: node0314.palmetto.clemson.edu\n",
      "Slave Nodes:\n",
      "node0317.palmetto.clemson.edu\n",
      "node0355.palmetto.clemson.edu\n",
      "node0442.palmetto.clemson.edu\n",
      "Temporary dir: /local_scratch/pbs.8742780.pbs02\n",
      "Memory per worker (GB): 13G\n",
      "Cores per worker: 8\n",
      "Num workers: 3\n",
      ". /home/aamle/software/spark-2.4.5-bin-hadoop2.7/sbin/start-all.sh -h node0314.palmetto.clemson.edu -d /local_scratch/pbs.8742780.pbs02 -m 13G -c 3\n",
      "starting org.apache.spark.deploy.master.Master, logging to /home/aamle/software/spark-2.4.5-bin-hadoop2.7/logs/spark-aamle-org.apache.spark.deploy.master.Master-1-node0314.palmetto.clemson.edu.out\n",
      "node0317.palmetto.clemson.edu: starting org.apache.spark.deploy.worker.Worker, logging to /home/aamle/software/spark-2.4.5-bin-hadoop2.7/logs/spark-aamle-org.apache.spark.deploy.worker.Worker-1-node0317.palmetto.clemson.edu.out\n",
      "node0355.palmetto.clemson.edu: starting org.apache.spark.deploy.worker.Worker, logging to /home/aamle/software/spark-2.4.5-bin-hadoop2.7/logs/spark-aamle-org.apache.spark.deploy.worker.Worker-1-node0355.palmetto.clemson.edu.out\n",
      "node0442.palmetto.clemson.edu: starting org.apache.spark.deploy.worker.Worker, logging to /home/aamle/software/spark-2.4.5-bin-hadoop2.7/logs/spark-aamle-org.apache.spark.deploy.worker.Worker-1-node0442.palmetto.clemson.edu.out\n"
     ]
    }
   ],
   "source": [
    "!bash launch_spark_cluster.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=spark://node0314.palmetto.clemson.edu:7077 appName=big-data-workshop>\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pyspark\n",
    "\n",
    "env_spark_home=os.path.join(os.environ['HOME'],\"software\",\"spark-2.4.5-bin-hadoop2.7\")\n",
    "env_spark_conf_dir=os.path.join(env_spark_home,\"conf\")\n",
    "env_pyspark_python=os.path.join(\"/software\",\"anaconda3\",\"5.1.0\",\"bin\",\"python\")\n",
    "\n",
    "os.environ['SPARK_HOME'] = env_spark_home\n",
    "os.environ['SPARK_CONF_DIR'] = env_spark_conf_dir\n",
    "os.environ['PYSPARK_PYTHON'] = env_pyspark_python\n",
    "\n",
    "fp = open(os.path.join(env_spark_conf_dir,\"master\"))\n",
    "node_list = fp.readlines()\n",
    "\n",
    "import pyspark\n",
    "conf = pyspark.SparkConf()\n",
    "conf.setMaster(\"spark://\" + node_list[0].strip() + \":7077\")\n",
    "conf.setAppName('big-data-workshop')\n",
    "conf.set(\"spark.driver.memory\",\"5g\")\n",
    "conf.set(\"spark.executor.instances\", \"3\")\n",
    "conf.set(\"spark.executor.memory\",\"13g\")\n",
    "conf.set(\"spark.executor.cores\",\"8\")\n",
    "\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "\n",
    "print(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Airlines Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spark SQL**\n",
    "- Spark module for structured data processing\n",
    "- provides more information about the structure of both the data and the computation being performed for additional optimization\n",
    "- execute SQL queries written using either a basic SQL syntax or HiveQL\n",
    "\n",
    "**DataFrame**\n",
    "- a distributed collection of data organized into named columns\n",
    "- conceptually equivalent to a table in a relational database or a data frame in R/Python, but with richer optimizations under the hood\n",
    "- can be constructed from a wide array of sources such as: structured data files, tables in Hive, external databases, or existing RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.context.SQLContext at 0x15251e6f3ef0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext = pyspark.SQLContext(sc)\n",
    "sqlContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines = sqlContext.read.format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferschema\", \"true\")\\\n",
    "    .load(\"/zfs/citi/airlines/data/\")\\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.33 ms, sys: 6.86 ms, total: 15.2 ms\n",
      "Wall time: 2min 16s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "123534969"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "airlines.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 217 Âµs, sys: 2.76 ms, total: 2.98 ms\n",
      "Wall time: 285 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "123534969"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "airlines.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- DayofMonth: integer (nullable = true)\n",
      " |-- DayOfWeek: integer (nullable = true)\n",
      " |-- DepTime: string (nullable = true)\n",
      " |-- CRSDepTime: integer (nullable = true)\n",
      " |-- ArrTime: string (nullable = true)\n",
      " |-- CRSArrTime: integer (nullable = true)\n",
      " |-- UniqueCarrier: string (nullable = true)\n",
      " |-- FlightNum: integer (nullable = true)\n",
      " |-- TailNum: string (nullable = true)\n",
      " |-- ActualElapsedTime: string (nullable = true)\n",
      " |-- CRSElapsedTime: string (nullable = true)\n",
      " |-- AirTime: string (nullable = true)\n",
      " |-- ArrDelay: string (nullable = true)\n",
      " |-- DepDelay: string (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- Dest: string (nullable = true)\n",
      " |-- Distance: string (nullable = true)\n",
      " |-- TaxiIn: string (nullable = true)\n",
      " |-- TaxiOut: string (nullable = true)\n",
      " |-- Cancelled: integer (nullable = true)\n",
      " |-- CancellationCode: string (nullable = true)\n",
      " |-- Diverted: integer (nullable = true)\n",
      " |-- CarrierDelay: string (nullable = true)\n",
      " |-- WeatherDelay: string (nullable = true)\n",
      " |-- NASDelay: string (nullable = true)\n",
      " |-- SecurityDelay: string (nullable = true)\n",
      " |-- LateAircraftDelay: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airlines.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can interact with a DataFrame via SQLContext using SQL statements by registering the DataFrame as a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.registerTempTable(\"airlines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*How many unique airlines are there?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|UniqueCarrier|\n",
      "+-------------+\n",
      "|           UA|\n",
      "|           EA|\n",
      "|           PI|\n",
      "|           PS|\n",
      "|           AA|\n",
      "|           NW|\n",
      "|           EV|\n",
      "|           B6|\n",
      "|           HP|\n",
      "|           TW|\n",
      "|           DL|\n",
      "|           OO|\n",
      "|           F9|\n",
      "|           YV|\n",
      "|           TZ|\n",
      "|           US|\n",
      "|           AQ|\n",
      "|           MQ|\n",
      "|           OH|\n",
      "|           HA|\n",
      "+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "uniqueAirline = sqlContext.sql(\"SELECT DISTINCT UniqueCarrier \\\n",
    "                                FROM airlines\")\n",
    "uniqueAirline.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Calculate how many flights completed by each carrier over time*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+\n",
      "|UniqueCarrier|FlightCount|\n",
      "+-------------+-----------+\n",
      "|           UA|   13299817|\n",
      "|           EA|     919785|\n",
      "|           PI|     873957|\n",
      "|           PS|      83617|\n",
      "|           AA|   14984647|\n",
      "|           NW|   10292627|\n",
      "|           EV|    1697172|\n",
      "|           B6|     811341|\n",
      "|           HP|    3636682|\n",
      "|           TW|    3757747|\n",
      "|           DL|   16547870|\n",
      "|           OO|    3090853|\n",
      "|           F9|     336958|\n",
      "|           YV|     854056|\n",
      "|           TZ|     208420|\n",
      "|           AQ|     154381|\n",
      "|           US|   14075530|\n",
      "|           MQ|    3954895|\n",
      "|           OH|    1464176|\n",
      "|           HA|     274265|\n",
      "+-------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 3.32 ms, sys: 670 Âµs, total: 3.99 ms\n",
      "Wall time: 3.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "carrierFlightCount = sqlContext.sql(\"SELECT UniqueCarrier, COUNT(UniqueCarrier) AS FlightCount \\\n",
    "                                    FROM airlines GROUP BY UniqueCarrier\")\n",
    "carrierFlightCount.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*How do you display full carrier names?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "carriers = sqlContext.read.format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferschema\", \"true\")\\\n",
    "    .load(\"/zfs/citi/airlines/metadata/carriers.csv\")\\\n",
    "    .cache()\n",
    "carriers.registerTempTable(\"carriers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Code: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "carriers.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+-----------+\n",
      "|         Description|UniqueCarrier|FlightCount|\n",
      "+--------------------+-------------+-----------+\n",
      "|Pinnacle Airlines...|           9E|     521059|\n",
      "|American Airlines...|           AA|   14984647|\n",
      "| Aloha Airlines Inc.|           AQ|     154381|\n",
      "|Alaska Airlines Inc.|           AS|    2878021|\n",
      "|     JetBlue Airways|           B6|     811341|\n",
      "|Continental Air L...|           CO|    8145788|\n",
      "|    Independence Air|           DH|     693047|\n",
      "|Delta Air Lines Inc.|           DL|   16547870|\n",
      "|Eastern Air Lines...|           EA|     919785|\n",
      "|Atlantic Southeas...|           EV|    1697172|\n",
      "|Frontier Airlines...|           F9|     336958|\n",
      "|AirTran Airways C...|           FL|    1265138|\n",
      "|Hawaiian Airlines...|           HA|     274265|\n",
      "|America West Airl...|           HP|    3636682|\n",
      "|Midway Airlines I...|       ML (1)|      70622|\n",
      "|American Eagle Ai...|           MQ|    3954895|\n",
      "|Northwest Airline...|           NW|   10292627|\n",
      "|         Comair Inc.|           OH|    1464176|\n",
      "|Skywest Airlines ...|           OO|    3090853|\n",
      "|Pan American Worl...|       PA (1)|     316167|\n",
      "+--------------------+-------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 2.36 ms, sys: 1.97 ms, total: 4.34 ms\n",
      "Wall time: 9.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "carrierFlightCountFullName = sqlContext.sql(\"SELECT c.Description, a.UniqueCarrier, COUNT(a.UniqueCarrier) AS FlightCount \\\n",
    "                                    FROM airlines AS a \\\n",
    "                                    INNER JOIN carriers AS c \\\n",
    "                                    ON c.Code = a.UniqueCarrier \\\n",
    "                                    GROUP BY a.UniqueCarrier, c.Description \\\n",
    "                                    ORDER BY a.UniqueCarrier\")\n",
    "carrierFlightCountFullName.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What is the averaged departure delay time for each airline?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+---------------------------+-------------------+\n",
      "|first(Description, false)|first(UniqueCarrier, false)|        AvgDepDelay|\n",
      "+-------------------------+---------------------------+-------------------+\n",
      "|     Pinnacle Airlines...|                         9E| 7.9279144892173035|\n",
      "|     American Airlines...|                         AA|  7.862321254420546|\n",
      "|      Aloha Airlines Inc.|                         AQ| 1.5993176899118409|\n",
      "|     Alaska Airlines Inc.|                         AS|  8.297235193754096|\n",
      "|          JetBlue Airways|                         B6| 11.262714178314551|\n",
      "|     Continental Air L...|                         CO|  7.695967155526857|\n",
      "|         Independence Air|                         DH|  9.612639389688926|\n",
      "|     Delta Air Lines Inc.|                         DL|  7.593716274369933|\n",
      "|     Eastern Air Lines...|                         EA|  8.674050565435543|\n",
      "|     Atlantic Southeas...|                         EV| 13.483736343326541|\n",
      "|     Frontier Airlines...|                         F9|  6.096932123645889|\n",
      "|     AirTran Airways C...|                         FL|  10.27801937883596|\n",
      "|     Hawaiian Airlines...|                         HA|-0.5165400834606493|\n",
      "|     America West Airl...|                         HP|  8.107790266585615|\n",
      "|     Midway Airlines I...|                     ML (1)|  6.229676674364896|\n",
      "|     American Eagle Ai...|                         MQ|   9.22369994420141|\n",
      "|     Northwest Airline...|                         NW|  6.007973703240084|\n",
      "|              Comair Inc.|                         OH|  9.310795113723774|\n",
      "|     Skywest Airlines ...|                         OO|  7.193778047766392|\n",
      "|     Pan American Worl...|                     PA (1)|  5.532442442890681|\n",
      "+-------------------------+---------------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 2.07 ms, sys: 3.01 ms, total: 5.08 ms\n",
      "Wall time: 17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "avgDepartureDelay = sqlContext.sql(\"SELECT FIRST(c.Description), FIRST(a.UniqueCarrier), AVG(a.DepDelay) AS AvgDepDelay \\\n",
    "                                    FROM airlines AS a \\\n",
    "                                    INNER JOIN carriers AS c \\\n",
    "                                    ON c.Code = a.UniqueCarrier \\\n",
    "                                    GROUP BY a.UniqueCarrier \\\n",
    "                                    ORDER BY a.UniqueCarrier\")\n",
    "avgDepartureDelay.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Year: int, Month: int, DayofMonth: int, DayOfWeek: int, DepTime: string, CRSDepTime: int, ArrTime: string, CRSArrTime: int, UniqueCarrier: string, FlightNum: int, TailNum: string, ActualElapsedTime: string, CRSElapsedTime: string, AirTime: string, ArrDelay: string, DepDelay: string, Origin: string, Dest: string, Distance: string, TaxiIn: string, TaxiOut: string, Cancelled: int, CancellationCode: string, Diverted: int, CarrierDelay: string, WeatherDelay: string, NASDelay: string, SecurityDelay: string, LateAircraftDelay: string]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Spark cluster:\n",
      "node0355.palmetto.clemson.edu: stopping org.apache.spark.deploy.worker.Worker\n",
      "node0317.palmetto.clemson.edu: stopping org.apache.spark.deploy.worker.Worker\n",
      "node0442.palmetto.clemson.edu: stopping org.apache.spark.deploy.worker.Worker\n",
      "stopping org.apache.spark.deploy.master.Master\n"
     ]
    }
   ],
   "source": [
    "!bash stop_spark_cluster.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Anaconda 5.1.0)",
   "language": "python",
   "name": "anaconda3-5.1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
